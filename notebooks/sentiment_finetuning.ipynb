{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis Fine-tuning for Restaurant Reviews\n",
    "\n",
    "This notebook fine-tunes DistilBERT for sentiment analysis on Zomato restaurant reviews.\n",
    "\n",
    "**Steps:**\n",
    "1. Load and preprocess Zomato reviews\n",
    "2. Create balanced dataset with proper labels\n",
    "3. Fine-tune DistilBERT\n",
    "4. Save model to `models/sentiment/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model checkpoint: distilbert-base-uncased\n",
      "Save path: models/sentiment/final_model\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "RAW_DATA_PATH = '/Users/swarnendubanik/Desktop/AI powered restaurant/data/raw/zomato2.csv'\n",
    "MODEL_SAVE_PATH = 'models/sentiment/final_model'\n",
    "\n",
    "# Model config\n",
    "MODEL_CHECKPOINT = 'distilbert-base-uncased'\n",
    "\n",
    "# Training config\n",
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_EPOCHS = 3\n",
    "SAMPLE_SIZE = 10000  # Number of restaurants to sample\n",
    "\n",
    "# Labels (binary classification like movie reviews)\n",
    "id2label = {0: \"Negative\", 1: \"Positive\"}\n",
    "label2id = {\"Negative\": 0, \"Positive\": 1}\n",
    "\n",
    "print(f\"Model checkpoint: {MODEL_CHECKPOINT}\")\n",
    "print(f\"Save path: {MODEL_SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load and Preprocess Zomato Reviews\n",
    "\n",
    "The `reviews_list` column contains a list of tuples: `[(\"Rated X.X\", \"review text\"), ...]`\n",
    "\n",
    "We need to:\n",
    "1. Parse the string representation to actual list\n",
    "2. Extract rating and review text\n",
    "3. Convert rating to binary label: ≥4 → Positive, <3 → Negative (skip neutral 3-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw data...\n",
      "Total restaurants: 51,717\n",
      "Sampled: 10,000 restaurants\n"
     ]
    }
   ],
   "source": [
    "# Load raw data\n",
    "print(\"Loading raw data...\")\n",
    "df = pd.read_csv(\"/Users/swarnendubanik/Desktop/AI powered restaurant/data/raw/zomato2.csv\")\n",
    "print(f\"Total restaurants: {len(df):,}\")\n",
    "\n",
    "# Sample for faster processing\n",
    "if SAMPLE_SIZE and SAMPLE_SIZE < len(df):\n",
    "    df = df.sample(n=SAMPLE_SIZE, random_state=42)\n",
    "    print(f\"Sampled: {len(df):,} restaurants\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample parsed reviews: 5 reviews\n",
      "First review: Rating=3.0, Text=A pocket friendly food joint in the locality to have odia cuisine.\n",
      "\n",
      "But it is very small and congest...\n"
     ]
    }
   ],
   "source": [
    "def parse_reviews(reviews_str):\n",
    "    \"\"\"\n",
    "    Parse the reviews_list column and extract (rating, text) pairs.\n",
    "    \"\"\"\n",
    "    if pd.isna(reviews_str) or reviews_str == '[]':\n",
    "        return []\n",
    "    \n",
    "    try:\n",
    "        # Safely evaluate the string representation\n",
    "        reviews = ast.literal_eval(str(reviews_str))\n",
    "        \n",
    "        parsed = []\n",
    "        for rating_str, review_text in reviews:\n",
    "            # Extract numeric rating from \"Rated 4.0\"\n",
    "            rating_match = re.search(r'(\\d+\\.?\\d*)', rating_str)\n",
    "            if not rating_match:\n",
    "                continue\n",
    "            rating = float(rating_match.group(1))\n",
    "            \n",
    "            # Clean review text - remove \"RATED\\n\" prefix\n",
    "            clean_text = str(review_text).replace('RATED\\n', '').replace('RATED\\\\n', '').strip()\n",
    "            \n",
    "            # Skip empty or very short reviews\n",
    "            if not clean_text or len(clean_text) < 20:\n",
    "                continue\n",
    "            \n",
    "            parsed.append((rating, clean_text))\n",
    "        \n",
    "        return parsed\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "# Test parsing\n",
    "sample_reviews = df['reviews_list'].iloc[0]\n",
    "parsed = parse_reviews(sample_reviews)\n",
    "print(f\"Sample parsed reviews: {len(parsed)} reviews\")\n",
    "if parsed:\n",
    "    print(f\"First review: Rating={parsed[0][0]}, Text={parsed[0][1][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting reviews from dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 6554.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total reviews extracted: 196,890\n",
      "Class distribution:\n",
      "  Positive (1): 154,598\n",
      "  Negative (0): 42,292\n"
     ]
    }
   ],
   "source": [
    "def extract_all_reviews(df):\n",
    "    \"\"\"\n",
    "    Extract all reviews from dataframe and create labeled dataset.\n",
    "    Binary labels: rating >= 4 → Positive (1), rating < 3 → Negative (0)\n",
    "    We skip neutral reviews (3-4) to get cleaner training signal.\n",
    "    \"\"\"\n",
    "    all_reviews = []\n",
    "    \n",
    "    print(\"Extracting reviews from dataset...\")\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        reviews = parse_reviews(row['reviews_list'])\n",
    "        \n",
    "        for rating, text in reviews:\n",
    "            # Binary labeling (skip 3-4 range for clearer signal)\n",
    "            if rating >= 4:\n",
    "                label = 1  # Positive\n",
    "            elif rating < 3:\n",
    "                label = 0  # Negative\n",
    "            else:\n",
    "                continue  # Skip neutral (3-4)\n",
    "            \n",
    "            # Truncate very long reviews\n",
    "            text = text[:1000]\n",
    "            \n",
    "            all_reviews.append({\n",
    "                'text': text,\n",
    "                'label': label\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(all_reviews)\n",
    "\n",
    "# Extract all reviews\n",
    "reviews_df = extract_all_reviews(df)\n",
    "print(f\"\\nTotal reviews extracted: {len(reviews_df):,}\")\n",
    "print(f\"Class distribution:\")\n",
    "print(f\"  Positive (1): {(reviews_df['label'] == 1).sum():,}\")\n",
    "print(f\"  Negative (0): {(reviews_df['label'] == 0).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balancing to 42,292 samples per class\n",
      "\n",
      "Balanced dataset size: 84,584\n"
     ]
    }
   ],
   "source": [
    "# Balance the dataset by undersampling the majority class\n",
    "def balance_dataset(df):\n",
    "    positive = df[df['label'] == 1]\n",
    "    negative = df[df['label'] == 0]\n",
    "    \n",
    "    min_samples = min(len(positive), len(negative))\n",
    "    print(f\"Balancing to {min_samples:,} samples per class\")\n",
    "    \n",
    "    positive_sampled = positive.sample(n=min_samples, random_state=42)\n",
    "    negative_sampled = negative.sample(n=min_samples, random_state=42)\n",
    "    \n",
    "    balanced = pd.concat([positive_sampled, negative_sampled])\n",
    "    balanced = balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    return balanced\n",
    "\n",
    "balanced_df = balance_dataset(reviews_df)\n",
    "print(f\"\\nBalanced dataset size: {len(balanced_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample positive review:\n",
      "  Great place in the midst of a busy city. Good view of the city with a great ambience and extremely couteous staff. We tried Mutton Chaap and it was really amazing. Awadhi chicken with kadak roti and t...\n",
      "\n",
      "Sample negative review:\n",
      "  They got parts of the order wrong, twice! The food was average. The decor looks fancy mainly in pics. Overall unimpressed with this place.. Highly rated for cocktails but expected great food for the p...\n"
     ]
    }
   ],
   "source": [
    "# View sample data\n",
    "print(\"Sample positive review:\")\n",
    "pos_sample = balanced_df[balanced_df['label'] == 1].iloc[0]\n",
    "print(f\"  {pos_sample['text'][:200]}...\")\n",
    "\n",
    "print(\"\\nSample negative review:\")\n",
    "neg_sample = balanced_df[balanced_df['label'] == 0].iloc[0]\n",
    "print(f\"  {neg_sample['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create HuggingFace Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 67,667\n",
      "Validation samples: 16,917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 67667\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__'],\n",
       "        num_rows: 16917\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(\n",
    "    balanced_df, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=balanced_df['label']\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_df):,}\")\n",
    "print(f\"Validation samples: {len(val_df):,}\")\n",
    "\n",
    "# Create HuggingFace datasets\n",
    "train_dataset = Dataset.from_pandas(train_df[['text', 'label']])\n",
    "val_dataset = Dataset.from_pandas(val_df[['text', 'label']])\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5000073891261619)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display % of training data with label=1\n",
    "np.array(dataset['train']['label']).sum() / len(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f359eb43d847a284c5c8539201b6bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DistilBertForSequenceClassification LOAD REPORT from: distilbert-base-uncased\n",
      "Key                     | Status     | \n",
      "------------------------+------------+-\n",
      "vocab_transform.bias    | UNEXPECTED | \n",
      "vocab_layer_norm.bias   | UNEXPECTED | \n",
      "vocab_projector.bias    | UNEXPECTED | \n",
      "vocab_transform.weight  | UNEXPECTED | \n",
      "vocab_layer_norm.weight | UNEXPECTED | \n",
      "pre_classifier.bias     | MISSING    | \n",
      "pre_classifier.weight   | MISSING    | \n",
      "classifier.bias         | MISSING    | \n",
      "classifier.weight       | MISSING    | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    }
   ],
   "source": [
    "# Load model for binary classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_CHECKPOINT, \n",
    "    num_labels=2, \n",
    "    id2label=id2label, \n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSelfAttention(\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 30522\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT, add_prefix_space=True)\n",
    "\n",
    "# Add pad token if it doesn't exist\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "print(f\"Vocab size: {len(tokenizer)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Tokenize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    text = examples[\"text\"]\n",
    "    \n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "    \n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdcd36c40b14fc4a9a27172a0b6b139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/67667 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57985d23fc604422a03aeeefc459ba3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/16917 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 67667\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 16917\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collator for padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # accuracy.compute() already returns {\"accuracy\": value}, so unpack it\n",
    "    result = accuracy.compute(predictions=predictions, references=labels)\n",
    "    return result  # Returns: {\"accuracy\": 0.85} - FLAT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Test Untrained Model (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on: mps:0\n",
      "\n",
      "Untrained model predictions:\n",
      "  Positive: The food was absolutely delicious! Best restaurant...\n",
      "  Negative: Terrible experience. Food was cold and service was...\n",
      "  Positive: Amazing ambiance and the pasta was incredible....\n",
      "  Negative: Worst biryani I've ever had. Never coming back....\n",
      "  Positive: Loved the desserts! Will definitely visit again....\n"
     ]
    }
   ],
   "source": [
    "# Test with sample texts\n",
    "text_list = [\n",
    "    \"The food was absolutely delicious! Best restaurant ever.\",\n",
    "    \"Terrible experience. Food was cold and service was rude.\",\n",
    "    \"Amazing ambiance and the pasta was incredible.\",\n",
    "    \"Worst biryani I've ever had. Never coming back.\",\n",
    "    \"Loved the desserts! Will definitely visit again.\"\n",
    "]\n",
    "\n",
    "# Get model's device\n",
    "device = next(model.parameters()).device\n",
    "print(f\"Model is on: {device}\")\n",
    "\n",
    "print(\"\\nUntrained model predictions:\")\n",
    "for text in text_list:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=MAX_LENGTH)\n",
    "    \n",
    "    # Move inputs to same device as model\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
    "    \n",
    "    print(f\"  {id2label[prediction]}: {text[:50]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warmup_ratio is deprecated and will be removed in v5.2. Use `warmup_steps` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 67667\n",
      "Steps per epoch: 4229\n",
      "Eval every 1057 steps (0.25 epoch)\n"
     ]
    }
   ],
   "source": [
    "# Calculate steps for 0.25 epoch validation\n",
    "train_samples = len(tokenized_dataset['train'])\n",
    "steps_per_epoch = train_samples // BATCH_SIZE\n",
    "eval_steps = int(steps_per_epoch * 0.25)  # Validate every 0.25 epoch\n",
    "\n",
    "print(f\"Total training samples: {train_samples}\")\n",
    "print(f\"Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"Eval every {eval_steps} steps (0.25 epoch)\")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_SAVE_PATH + \"_checkpoints\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"steps\",           # Changed from \"epoch\"\n",
    "    eval_steps=eval_steps,            # Validate every 0.25 epoch\n",
    "    save_strategy=\"steps\",            # Changed from \"epoch\"\n",
    "    save_steps=eval_steps,            # Save at same frequency\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    logging_steps=50,\n",
    "    warmup_ratio=0.1,\n",
    "    report_to=\"none\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12690' max='12690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12690/12690 53:20, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1057</td>\n",
       "      <td>0.037075</td>\n",
       "      <td>0.075195</td>\n",
       "      <td>0.988000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2114</td>\n",
       "      <td>0.054145</td>\n",
       "      <td>0.063448</td>\n",
       "      <td>0.983567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3171</td>\n",
       "      <td>0.013227</td>\n",
       "      <td>0.069971</td>\n",
       "      <td>0.988118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4228</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.058152</td>\n",
       "      <td>0.990010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5285</td>\n",
       "      <td>0.016014</td>\n",
       "      <td>0.047548</td>\n",
       "      <td>0.991783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6342</td>\n",
       "      <td>0.007035</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.992670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7399</td>\n",
       "      <td>0.018118</td>\n",
       "      <td>0.053179</td>\n",
       "      <td>0.991665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8456</td>\n",
       "      <td>0.015376</td>\n",
       "      <td>0.045148</td>\n",
       "      <td>0.993793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9513</td>\n",
       "      <td>0.003839</td>\n",
       "      <td>0.052602</td>\n",
       "      <td>0.992552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10570</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.054223</td>\n",
       "      <td>0.993793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11627</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.051955</td>\n",
       "      <td>0.993734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12684</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.050910</td>\n",
       "      <td>0.993911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ce0eef3bdf452b89157e7a94b1e751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/AIrestaurant/lib/python3.10/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8231f68e9054ec799907af548da34ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/AIrestaurant/lib/python3.10/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c25aa35e0454d918e289e16fb1afb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/AIrestaurant/lib/python3.10/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b121c45839bb4fff8313838e082b07f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/AIrestaurant/lib/python3.10/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316372783689453dbabd5e0c1ca42eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/AIrestaurant/lib/python3.10/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f50b93c138c4f69b8911f1b835edc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/AIrestaurant/lib/python3.10/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63baa0dcd1c244799bde808a28ce57fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/AIrestaurant/lib/python3.10/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f2960a0ac9415c80820aa94a48891b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/AIrestaurant/lib/python3.10/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c965e1be5dfb4536a700aa578aea7206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/AIrestaurant/lib/python3.10/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b49c53b47f84175967a232d537fc362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/AIrestaurant/lib/python3.10/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718141ae1dbf4922a9e1bf43f22697cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/AIrestaurant/lib/python3.10/site-packages/torch/utils/data/dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74207fcf0c0a4d8d9d4874933ed03379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b40dc03220cb4c979839474f8a5df7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias'].\n",
      "There were unexpected keys in the checkpoint model loaded: ['distilbert.embeddings.LayerNorm.beta', 'distilbert.embeddings.LayerNorm.gamma'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12690, training_loss=0.014613968513390802, metrics={'train_runtime': 3200.5317, 'train_samples_per_second': 63.427, 'train_steps_per_second': 3.965, 'total_flos': 9892669729961676.0, 'train_loss': 0.014613968513390802, 'epoch': 3.0})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Results:\n",
      "  Accuracy: 0.9939\n",
      "  Loss: 0.0509\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"\\nValidation Results:\")\n",
    "print(f\"  Accuracy: {eval_results['eval_accuracy']:.4f}\")  # Remove ['accuracy']\n",
    "print(f\"  Loss: {eval_results['eval_loss']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Test Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model predictions:\n",
      "  Positive (100.00%): The food was absolutely delicious! Best restaurant...\n",
      "  Negative (100.00%): Terrible experience. Food was cold and service was...\n",
      "  Positive (100.00%): Amazing ambiance and the pasta was incredible....\n",
      "  Negative (100.00%): Worst biryani I've ever had. Never coming back....\n",
      "  Positive (100.00%): Loved the desserts! Will definitely visit again....\n"
     ]
    }
   ],
   "source": [
    "# Test with sample texts\n",
    "print(\"Trained model predictions:\")\n",
    "for text in text_list:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=MAX_LENGTH)\n",
    "    \n",
    "    # Move to same device as model\n",
    "    device = next(model.parameters()).device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=-1)\n",
    "        prediction = torch.argmax(probs, dim=-1).item()\n",
    "        confidence = probs[0][prediction].item()\n",
    "    \n",
    "    print(f\"  {id2label[prediction]} ({confidence:.2%}): {text[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Zomato review predictions:\n",
      "  Positive (100.00%): The biryani was amazing! Perfect spices and tender meat. Mus...\n",
      "  Negative (100.00%): Pathetic service. Waited 45 minutes for cold food. Staff was...\n",
      "  Positive (100.00%): Great ambiance for a romantic dinner. The pasta was creamy a...\n",
      "  Negative (100.00%): Overpriced and underwhelming. The pizza was soggy and tastel...\n",
      "  Positive (100.00%): Loved the live music and the cocktails. Perfect weekend hang...\n"
     ]
    }
   ],
   "source": [
    "# Test with actual Zomato reviews\n",
    "zomato_test_reviews = [\n",
    "    \"The biryani was amazing! Perfect spices and tender meat. Must visit for biryani lovers.\",\n",
    "    \"Pathetic service. Waited 45 minutes for cold food. Staff was extremely rude.\",\n",
    "    \"Great ambiance for a romantic dinner. The pasta was creamy and delicious.\",\n",
    "    \"Overpriced and underwhelming. The pizza was soggy and tasteless.\",\n",
    "    \"Loved the live music and the cocktails. Perfect weekend hangout spot!\"\n",
    "]\n",
    "\n",
    "print(\"\\nZomato review predictions:\")\n",
    "for text in zomato_test_reviews:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=MAX_LENGTH)\n",
    "    device = next(model.parameters()).device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=-1)\n",
    "        prediction = torch.argmax(probs, dim=-1).item()\n",
    "        confidence = probs[0][prediction].item()\n",
    "    \n",
    "    print(f\"  {id2label[prediction]} ({confidence:.2%}): {text[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: models/sentiment/final_model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f250148c28a4d28a3779fea9f323371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "Path(MODEL_SAVE_PATH).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save the model and tokenizer\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "trainer.save_model(MODEL_SAVE_PATH)\n",
    "tokenizer.save_pretrained(MODEL_SAVE_PATH)\n",
    "\n",
    "# Save training info\n",
    "import json\n",
    "\n",
    "training_info = {\n",
    "    \"base_model\": MODEL_CHECKPOINT,\n",
    "    \"num_epochs\": NUM_EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"max_length\": MAX_LENGTH,\n",
    "    \"train_samples\": len(train_df),\n",
    "    \"val_samples\": len(val_df),\n",
    "    \"eval_accuracy\": eval_results['eval_accuracy'],\n",
    "    \"id2label\": id2label,\n",
    "    \"label2id\": label2id\n",
    "}\n",
    "\n",
    "with open(f\"{MODEL_SAVE_PATH}/training_info.json\", \"w\") as f:\n",
    "    json.dump(training_info, f, indent=2)\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Verify Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model for verification...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251fd2c590f2449680ac6c46db3c9912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model prediction: Positive\n",
      "   Test text: This restaurant has the best food I've ever tasted!\n"
     ]
    }
   ],
   "source": [
    "# Load and verify the saved model\n",
    "print(\"Loading saved model for verification...\")\n",
    "\n",
    "loaded_tokenizer = AutoTokenizer.from_pretrained(MODEL_SAVE_PATH)\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(MODEL_SAVE_PATH)\n",
    "\n",
    "# Test prediction\n",
    "test_text = \"This restaurant has the best food I've ever tasted!\"\n",
    "inputs = loaded_tokenizer(test_text, return_tensors=\"pt\", truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = loaded_model(**inputs)\n",
    "    prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
    "\n",
    "print(f\"Loaded model prediction: {id2label[prediction]}\")\n",
    "print(f\"   Test text: {test_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Training Complete!\n",
    "\n",
    "The sentiment model has been saved to `models/sentiment/final_model`\n",
    "\n",
    "You can now use this model in the restaurant recommendation agents."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIrestaurant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
